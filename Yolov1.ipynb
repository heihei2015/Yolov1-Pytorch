{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use VOC2012 dataset, you should download it, and put it in ../data.\n",
    "#And you also need create a folder called 'labels'\n",
    "DATA_PATH = \"../data/VOC2012/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we should transform the dataset.\n",
    "#We need the data type of (cls, x, y, w, h)\n",
    "CLASSES = ['person', 'bird', 'cat', 'cow', 'dog', 'horse', 'sheep',\n",
    "           'aeroplane', 'bicycle', 'boat', 'bus', 'car', 'motorbike', 'train',\n",
    "           'bottle', 'chair', 'dining table', 'potted plant', 'sofa', 'tvmonitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1. / size[0]\n",
    "    dh = 1. / size[1]\n",
    "    \n",
    "    x = (box[0] + box[1]) / 2.0\n",
    "    y = (box[2] + box[3]) / 2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    \n",
    "    x = x * dw\n",
    "    y = y * dh\n",
    "    w = w * dw\n",
    "    h = h * dh\n",
    "    \n",
    "    return (x, y, w ,h)\n",
    "\n",
    "def convert_annotation(image_id):\n",
    "    in_file = open(DATA_PATH + 'Annotations/%s' % image_id)\n",
    "    image_id = image_id.split('.')[0]\n",
    "    out_file = open('./labels/%s.txt' % image_id, 'w')\n",
    "    \n",
    "    tree = ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    \n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "    \n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        \n",
    "        if cls not in CLASSES or int(difficult) == 1:\n",
    "            continue\n",
    "        \n",
    "        cls_id = CLASSES.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        points = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text),\n",
    "             float(xmlbox.find('ymax').text))\n",
    "        convert_value = convert((w, h), points)\n",
    "        \n",
    "        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in convert_value]) + '\\n')\n",
    "\n",
    "def make_label_txt():\n",
    "    filenames = os.listdir(DATA_PATH + 'Annotations')\n",
    "    for file in filenames:\n",
    "        convert_annotation(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n"
     ]
    }
   ],
   "source": [
    "#Checkout the convert function\n",
    "def show_labels_img(img_name):\n",
    "    img = cv2.imread(DATA_PATH + 'JPEGImages/' + img_name + '.jpg')\n",
    "    h, w = img.shape[:2]\n",
    "    label = []\n",
    "    \n",
    "    with open('./labels/' + img_name + '.txt', 'r') as labels:\n",
    "        for label in labels:\n",
    "            label = label.split(' ')\n",
    "            label = [float(x.strip()) for x in label]\n",
    "            print(CLASSES[int(label[0])])\n",
    "            pt1 = (int(label[1] * w - label[3] * w / 2), int(label[2] * h - label[4] * h / 2))\n",
    "            pt2 = (int(label[1] * w + label[3] * w / 2), int(label[2] * h + label[4] * h / 2))\n",
    "            cv2.putText(img, CLASSES[int(label[0])], pt1, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255))\n",
    "            cv2.rectangle(img,pt1,pt2,(0,0,255,2))\n",
    "    \n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "make_label_txt()\n",
    "show_labels_img('2007_000027')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Prepare Pytorch Dataset.\n",
    "class VOC2012(Dataset):\n",
    "    def __init__(self, is_train=True, is_aug=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearning",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
